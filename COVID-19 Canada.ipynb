{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Go corona...corona go.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ADUzJd0ekHpD",
        "colab_type": "text"
      },
      "source": [
        "## **Coronavirus Canada Dashboard**\n",
        "\n",
        "Authors - Venkatesh Chandra and Ramy Hammam"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLL1HlXskVWi",
        "colab_type": "text"
      },
      "source": [
        "# Import all libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LieUuuwYj_Tu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import requests as rq\n",
        "import bs4 as bs\n",
        "from bs4 import BeautifulSoup as bs\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "url = (\"https://en.wikipedia.org/wiki/2020_coronavirus_pandemic_in_Canada\")\n",
        "\n",
        "res=rq.get(url)\n",
        "soup = bs(res.text, 'lxml')\n",
        "\n",
        "number_table = soup.find_all(\"table\", attrs={\"class\": \"wikitable\"})\n",
        "number_table_data = number_table[1].tbody.find_all(\"tr\")\n",
        "\n",
        "first_table=[]\n",
        "for i in range(2,50):\n",
        "  try:\n",
        "    if number_table_data[i].find(\"td\").text.replace('\\n', ' ').strip()!=\"vte\":\n",
        "        list1=[]\n",
        "        for td in number_table_data[i].find_all(\"td\"):\n",
        "            list1.append(td.text.replace('\\n', ' ').strip())\n",
        "        for th in number_table_data[i].find_all(\"th\"):\n",
        "            list1.append(th.text.replace('\\n', ' ').strip())\n",
        "        first_table.append(list1)\n",
        "    else:\n",
        "        break\n",
        "  except:\n",
        "        break\n",
        "\n",
        "column_names= ['BC', 'AB', 'SK'\t,'MB','ON','QC','NB','PE','NS','NL','YT', 'NT', 'NU', 'RT','Date','New-confirmed', 'Cum-confirmed','New-deaths','Cum-deaths','New-recoveries','Cum-recoveries','Source']\n",
        "\n",
        "df = pd.DataFrame(first_table, columns=column_names)\n",
        "\n",
        "dataset = df.iloc[:,:-1]\n",
        "dataset = dataset.replace(\"\", 0)\n",
        "\n",
        "df = dataset[['Date', 'Cum-confirmed', 'Cum-deaths', 'Cum-recoveries']]\n",
        "cum_dataset = df.melt(id_vars=['Date'], var_name='Cumulative Metric', value_name='Value')\n",
        "\n",
        "number_table1 = soup.find_all(\"table\", attrs={\"class\": \"wikitable\"})\n",
        "number_table_data1 = number_table1[2].tbody.find_all(\"tr\")\n",
        "\n",
        "\n",
        "second_table=[]\n",
        "for i in range(2,45):\n",
        "  try:\n",
        "    if number_table_data1[i].find(\"td\").text.replace('\\n', ' ').strip()!=\"vte\":\n",
        "        list1=[]\n",
        "        for td in number_table_data1[i].find_all(\"td\"):\n",
        "            list1.append(td.text.replace('\\n', ' ').strip())\n",
        "        for th in number_table_data1[i].find_all(\"th\"):\n",
        "            list1.append(th.text.replace('\\n', ' ').strip())\n",
        "        second_table.append(list1)\n",
        "    else:\n",
        "        break\n",
        "  except:\n",
        "        break\n",
        "\n",
        "column_names2= ['Province', 'Tests','Perk', \t'Conf.'\t,'Pres.',\t'Total','Population',\t'Per m', 'Recov.',\t'Deaths',\t'Active', 'BS']\n",
        "\n",
        "df2 = pd.DataFrame(second_table, columns=column_names2)\n",
        "\n",
        "dataset2 = df2.iloc[:,:-1]\n",
        "dataset2 = dataset2.replace(\"\", 0)\n",
        "dataset2['Per m'] = dataset2['Per m'].replace(\"N/A\", 0).astype(dtype=np.float64)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMCXtWH0WhHy",
        "colab_type": "code",
        "outputId": "dc6e8fe7-292a-482c-b441-d52054fe6dc9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('drive', force_remount=True)\n",
        "\n",
        "dataset.to_csv('corona_canada_meter1.csv')\n",
        "!cp corona_canada_meter1.csv \"drive/My Drive/\"\n",
        "\n",
        "cum_dataset.to_csv('cumulative_dataset1.csv')\n",
        "!cp cumulative_dataset1.csv \"drive/My Drive/\"\n",
        "\n",
        "dataset2.to_csv('province_second_table_dataset1.csv')\n",
        "!cp province_second_table_dataset1.csv \"drive/My Drive/\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QtfopdbpwuFj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}